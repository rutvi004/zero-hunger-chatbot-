# -*- coding: utf-8 -*-
"""Zero_hunger.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18rwKKFOmSqWaCBIG_6jKu5ad2f7GQsEg
"""

!pip install -qU google-generativeai==0.8.5 google-ai-generativelanguage==0.6.15 \
langgraph langchain langchain-google-genai openai

import os
import getpass
from langgraph.graph.message import add_messages
from langgraph.graph import StateGraph, END
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage,AIMessage
from typing_extensions import TypedDict
from typing import Annotated

os.environ["GOOGLE_API_KEY"] = getpass.getpass("Enter your Gemini API Key")

llm=ChatGoogleGenerativeAI(model="models/gemini-1.5-flash-latest",temperature=0.2)

class State(TypedDict):
    messages: Annotated[list, add_messages]
    classification: str
    need:str

def ask_need(state: State)->State:
  need = input("Hi! How can I assist you today regarding food security, nutrition, or sustainable agriculture?")
  state["need"] = need
  state["messages"] = [HumanMessage(content=need)] # Add user input as a HumanMessage
  return state

def classify_need(state: State):
    prompt = (
        "you are a helpful zero hunger promoter or agronomic or nutrition advisory.Classify the need below into of the categories:\n"
        "-Nutrition\n -Agriculture\n -Food Security\n"
        f"need :{state['need']}\n"
    )
    response = llm.invoke([HumanMessage(content=prompt)])
    category = response.content.strip()
    print(f"LLM Clasifies the need as:{category}") #debug
    state["classification"]=category
    return state

def need_router(state:State)-> str:
  last = state["classification"].lower()
  if "nutrition" in last:
        cat = "nutrition"
  elif "agriculture" in last or "farmer" in last:
        cat = "agriculture"
  elif "hunger" in last or "food security" in last:
        cat = "food_security"
  else:
        cat = "general"
  return cat



from langchain_core.messages import AIMessage, HumanMessage # Import HumanMessage

def respond_food_security(state: State):
    state["messages"] = state["messages"] + [AIMessage(content="Here’s help on reducing hunger and boosting food security...")] # Append to messages
    return state

def respond_nutrition(state: State):
    state["messages"] = state["messages"] + [AIMessage(content="Let’s talk about improving nutrition and dietary quality...")] # Append to messages
    return state

def respond_agriculture(state: State):
  state["messages"] = state["messages"] + [AIMessage(content="I can share sustainable agriculture practices and support for farmers...")] # Append to messages
  return state

def respond_general(state: State):
  state["messages"] = state["messages"] + [AIMessage(content="Could you please clarify if you're interested in hunger, nutrition, or sustainable agriculture?")] # Append to messages
  return state

from typing_extensions import TypedDict
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from typing import Annotated

class State(TypedDict):
    messages: Annotated[list, add_messages]
    classification: str
    need:str

graph = StateGraph(State)
graph.set_entry_point("ask_need")
graph.add_node("ask_need", ask_need)
graph.add_node("classify_need", classify_need)
graph.add_node("respond_food_security", respond_food_security)
graph.add_node("respond_nutrition", respond_nutrition)
graph.add_node("respond_agriculture", respond_agriculture)
graph.add_node("respond_general", respond_general)


graph.add_edge("ask_need", "classify_need")
graph.add_conditional_edges("classify_need", need_router, {
    "food_security": "respond_food_security",
    "nutrition": "respond_nutrition",
    "agriculture": "respond_agriculture",
    "general": "respond_general"
})
graph.add_edge("respond_food_security", END)
graph.add_edge("respond_nutrition", END)
graph.add_edge("respond_agriculture", END) # Typo fixed
graph.add_edge("respond_general", END)

app = graph.compile()



final_state=app.invoke({})
print("final output\n")
print(final_state["messages"])

